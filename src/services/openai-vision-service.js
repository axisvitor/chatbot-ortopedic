const axios = require('axios');
const { OPENAI_CONFIG } = require('../config/settings');
const { detectImageFormatFromBuffer } = require('../utils/image-format');

class OpenAIVisionService {
    constructor() {
        this.axios = axios.create({
            baseURL: OPENAI_CONFIG.baseUrl,
            headers: {
                'Authorization': `Bearer ${OPENAI_CONFIG.apiKey}`,
                'Content-Type': 'application/json'
            },
            timeout: 30000
        });
    }

    /**
     * Processa uma imagem e retorna a an√°lise
     * @param {Buffer} buffer Buffer da imagem
     * @param {Object} message Mensagem com informa√ß√µes adicionais
     * @param {number} attempt N√∫mero da tentativa (para retry)
     * @returns {Promise<Object>} Resultado da an√°lise
     */
    async processImage(buffer, message, attempt = 1) {
        try {
            // Detecta o formato da imagem
            const imageFormat = await detectImageFormatFromBuffer(buffer);
            if (!imageFormat) {
                throw new Error('Formato de imagem n√£o suportado');
            }

            // Converte o buffer para base64
            const base64Image = buffer.toString('base64');

            // Verifica o tamanho do payload base64
            const base64Size = base64Image.length * 0.75; // Tamanho aproximado em bytes
            if (base64Size > 20 * 1024 * 1024) { // 20MB limite OpenAI
                throw new Error('Imagem muito grande. M√°ximo permitido: 20MB');
            }

            // Monta o payload para a OpenAI Vision
            const payload = {
                model: OPENAI_CONFIG.models.vision,
                messages: [
                    {
                        role: 'user',
                        content: [
                            {
                                type: 'text',
                                text: 'Analise esta imagem em detalhes. Determine:\n' +
                                    '1. O tipo da imagem (comprovante de pagamento, foto de cal√ßado, foto de p√©s para medidas, tabela de medidas/numera√ß√£o)\n' +
                                    '2. Uma descri√ß√£o detalhada do que voc√™ v√™\n' +
                                    '3. Se for um comprovante de pagamento, extraia: valor, data e ID da transa√ß√£o\n' +
                                    (message?.extractedText ? `\nTexto extra√≠do via OCR: ${message.extractedText}` : '')
                            },
                            {
                                type: 'image_url',
                                image_url: {
                                    url: `data:${imageFormat};base64,${base64Image}`,
                                    detail: OPENAI_CONFIG.visionConfig.detail
                                }
                            }
                        ]
                    }
                ],
                ...OPENAI_CONFIG.visionConfig
            };

            console.log('üì§ Enviando imagem para an√°lise:', {
                imageFormat,
                base64Size: Math.round(base64Size / 1024) + 'KB',
                hasOCR: !!message?.extractedText,
                timestamp: new Date().toISOString()
            });

            const response = await this.axios.post('/chat/completions', payload);

            if (response.status !== 200) {
                console.error(`‚ùå Erro na API OpenAI (Tentativa ${attempt}):`, {
                    status: response.status,
                    data: response.data,
                    timestamp: new Date().toISOString()
                });
                throw new Error(`Erro na API OpenAI: ${response.status} - ${JSON.stringify(response.data)}`);
            }

            // Processa a resposta
            const content = response.data.choices[0].message.content;
            
            console.log('‚úÖ An√°lise conclu√≠da:', {
                responseLength: content.length,
                timestamp: new Date().toISOString()
            });

            return JSON.parse(content);

        } catch (error) {
            console.error(`‚ùå Erro ao processar imagem (Tentativa ${attempt}):`, {
                error: error.message,
                stack: error.stack,
                timestamp: new Date().toISOString()
            });

            // Tenta novamente se n√£o excedeu o n√∫mero m√°ximo de tentativas
            if (attempt < 3) {
                console.log(`üîÑ Tentando novamente (${attempt + 1}/3)...`);
                await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
                return this.processImage(buffer, message, attempt + 1);
            }

            throw error;
        }
    }

    /**
     * Analisa uma imagem usando base64
     * @param {string} base64Image Imagem em base64
     * @param {Object} options Op√ß√µes adicionais
     * @returns {Promise<Object>} Resultado da an√°lise
     */
    async analyzeImage(base64Image, options = {}) {
        try {
            console.log('üîç Iniciando an√°lise com OpenAI Vision...', {
                temCaption: !!options.caption,
                mimetype: options.mimetype
            });

            // Prepara o prompt para a an√°lise
            const prompt = this.buildAnalysisPrompt(options.caption);

            const payload = {
                model: OPENAI_CONFIG.models.vision,
                messages: [
                    {
                        role: 'user',
                        content: [
                            {
                                type: 'text',
                                text: prompt
                            },
                            {
                                type: 'image_url',
                                image_url: {
                                    url: `data:${options.mimetype || 'image/jpeg'};base64,${base64Image}`,
                                    detail: OPENAI_CONFIG.visionConfig.detail
                                }
                            }
                        ]
                    }
                ],
                ...OPENAI_CONFIG.visionConfig
            };

            console.log('üì§ Enviando requisi√ß√£o para OpenAI Vision...');
            const response = await this.axios.post('/chat/completions', payload);

            if (!response.data?.choices?.[0]?.message?.content) {
                throw new Error('Resposta inv√°lida da API OpenAI Vision');
            }

            console.log('‚úÖ An√°lise conclu√≠da com sucesso:', {
                statusCode: response.status,
                tamanhoResposta: JSON.stringify(response.data).length
            });

            return JSON.parse(response.data.choices[0].message.content);

        } catch (error) {
            console.error('‚ùå Erro na an√°lise com OpenAI Vision:', {
                erro: error.message,
                stack: error.stack,
                status: error.response?.status,
                resposta: error.response?.data
            });
            throw error;
        }
    }

    buildAnalysisPrompt(caption) {
        return `
            Analise esta imagem em detalhes. Se for um comprovante de pagamento, extraia as seguintes informa√ß√µes:
            - Valor da transa√ß√£o
            - Data da transa√ß√£o
            - Tipo de transa√ß√£o (PIX, transfer√™ncia, boleto, etc)
            - Status do pagamento
            - Informa√ß√µes adicionais relevantes

            Contexto adicional da imagem: ${caption || 'Nenhum'}

            Por favor, forne√ßa uma an√°lise detalhada e estruturada.
        `.trim();
    }
}

module.exports = { OpenAIVisionService }; 