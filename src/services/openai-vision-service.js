const axios = require('axios');
const { OPENAI_CONFIG } = require('../config/settings');
const { detectImageFormatFromBuffer } = require('../utils/image-format');

class OpenAIVisionService {
    constructor() {
        this.axios = axios.create({
            baseURL: OPENAI_CONFIG.baseUrl,
            headers: {
                'Authorization': `Bearer ${OPENAI_CONFIG.apiKey}`,
                'Content-Type': 'application/json'
            },
            timeout: 30000
        });
    }

    /**
     * Processa uma imagem usando o GPT-4 Vision API
     * @param {Object} message Mensagem contendo a imagem e informa√ß√µes adicionais
     * @returns {Promise<Object>} Resultado da an√°lise da imagem
     */
    async processImage(message) {
        try {
            // Valida√ß√£o inicial dos dados da imagem
            if (!message?.imageMessage?.base64 || !message?.imageMessage?.mimetype) {
                throw new Error('Mensagem inv√°lida: faltam dados da imagem');
            }

            console.log('üéØ [OpenAIVision] Iniciando processamento:', {
                messageId: message.key?.id,
                timestamp: new Date().toISOString()
            });

            // Garantir que o formato da imagem est√° correto
            const base64Image = message.imageMessage.base64;
            const mimeType = message.imageMessage.mimetype;

            // Construir a URL da imagem em base64
            const imageUrl = `data:${mimeType};base64,${base64Image}`;

            const payload = {
                model: "gpt-4o-mini",
                messages: [
                    {
                        role: "user",
                        content: [
                            {
                                type: "text",
                                text: message.imageMessage.caption || "Analise esta imagem em detalhes e descreva o que voc√™ v√™."
                            },
                            {
                                type: "image_url",
                                image_url: {
                                    url: imageUrl
                                }
                            }
                        ]
                    }
                ],
                max_tokens: 1000
            };

            console.log('üì§ [OpenAIVision] Enviando para API:', {
                messageId: message.key?.id,
                modelo: payload.model,
                mimeType: mimeType,
                timestamp: new Date().toISOString()
            });

            const response = await this.axios.post('/chat/completions', payload);

            // Valida√ß√£o da resposta usando optional chaining
            const content = response?.data?.choices?.[0]?.message?.content;
            if (!content) {
                console.error('‚ùå [OpenAIVision] Resposta inv√°lida:', {
                    messageId: message.key?.id,
                    status: response?.status,
                    data: response?.data
                });
                throw new Error('Resposta inv√°lida da API OpenAI Vision');
            }

            console.log('‚úÖ [OpenAIVision] An√°lise conclu√≠da:', {
                messageId: message.key?.id,
                tamanhoResposta: content.length,
                preview: content.substring(0, 100) + '...',
                timestamp: new Date().toISOString()
            });

            return {
                success: true,
                analysis: content,
                metadata: {
                    model: payload.model,
                    tokens: response.data.usage,
                    messageId: message.key?.id,
                    mimeType: mimeType
                }
            };

        } catch (error) {
            console.error('‚ùå [OpenAIVision] Erro ao processar imagem:', {
                messageId: message.key?.id,
                erro: error.message,
                stack: error.stack
            });
            throw error;
        }
    }

    /**
     * Analisa uma imagem usando base64
     * @param {string} base64Image Imagem em base64
     * @param {Object} options Op√ß√µes adicionais
     * @returns {Promise<Object>} Resultado da an√°lise
     */
    async analyzeImage(base64Image, options = {}) {
        try {
            console.log('üîç Iniciando an√°lise com OpenAI Vision...', {
                temCaption: !!options.caption,
                mimetype: options.mimetype
            });

            // Prepara o prompt para a an√°lise
            const prompt = this.buildAnalysisPrompt(options.caption);

            const payload = {
                model: OPENAI_CONFIG.models.vision,
                messages: [
                    {
                        role: 'user',
                        content: [
                            {
                                type: 'text',
                                text: prompt
                            },
                            {
                                type: 'image_url',
                                image_url: {
                                    url: `data:${options.mimetype || 'image/jpeg'};base64,${base64Image}`,
                                    detail: OPENAI_CONFIG.visionConfig.detail
                                }
                            }
                        ]
                    }
                ],
                ...OPENAI_CONFIG.visionConfig
            };

            console.log('üì§ Enviando requisi√ß√£o para OpenAI Vision...');
            const response = await this.axios.post('/chat/completions', payload);

            if (!response.data?.choices?.[0]?.message?.content) {
                throw new Error('Resposta inv√°lida da API OpenAI Vision');
            }

            console.log('‚úÖ An√°lise conclu√≠da com sucesso:', {
                statusCode: response.status,
                tamanhoResposta: JSON.stringify(response.data).length
            });

            return JSON.parse(response.data.choices[0].message.content);

        } catch (error) {
            console.error('‚ùå Erro na an√°lise com OpenAI Vision:', {
                erro: error.message,
                stack: error.stack,
                status: error.response?.status,
                resposta: error.response?.data
            });
            throw error;
        }
    }

    buildAnalysisPrompt(caption) {
        return `
            Analise esta imagem em detalhes. Se for um comprovante de pagamento, extraia as seguintes informa√ß√µes:
            - Valor da transa√ß√£o
            - Data da transa√ß√£o
            - Tipo de transa√ß√£o (PIX, transfer√™ncia, boleto, etc)
            - Status do pagamento
            - Informa√ß√µes adicionais relevantes

            Contexto adicional da imagem: ${caption || 'Nenhum'}

            Por favor, forne√ßa uma an√°lise detalhada e estruturada.
        `.trim();
    }
}

module.exports = { OpenAIVisionService };